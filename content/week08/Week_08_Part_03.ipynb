{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# These lines make warnings look nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Part 3 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Dependence ##\n",
    "We know:\n",
    "\n",
    "- $E(X_1 + X_2 + \\cdots + X_n) = E(X_1) + E(X_2) + \\cdots + E(X_n)$ for **all** $X_1, X_2, \\ldots, X_n$\n",
    "- $Var(X_1 + X_2 + \\cdots + X_n) = Var(X_1) + Var(X_2) + \\cdots + Var(X_n)$ for **independent** $X_1, X_2, \\ldots, X_n$\n",
    "\n",
    "If $X_1, X_2, \\ldots, X_n$ are *not* independent then we do have to calculate the covariance terms in the formula for the variance of the sum:\n",
    "\n",
    "$$\n",
    "Var(\\sum_{i=1}^n X_i) ~ = ~ \\sum_{i=1}^n Var(X_i) ~ + ~ \\mathop{\\sum\\sum}_{1 \\le i\\ne j \\le n} Cov(X_i, X_j)\n",
    "$$\n",
    "\n",
    "There are two situations in which the covariance terms are manageable:\n",
    "\n",
    "- If the random variables being added are indicators\n",
    "- If there is symmetry\n",
    "\n",
    "Let's start with indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading 1: Indicators ##\n",
    "Before you read, remember that if you have two 0/1 valued functions on the same space, then their product is also a 0/1 valued function. At any point in the domain, product is 1 if and only if both functions have the value 1 at that point.\n",
    "\n",
    "Now work through how to find the [covariance of two indicators](http://prob140.org/textbook/Chapter_13/03_Sums_of_Simple_Random_Samples.html#Indicators), including the discussion that connects the sign of the covariance and the direction of the association. \n",
    "\n",
    "You might want to make this set of rules the home screen on your phone or something equally important:\n",
    "\n",
    "For indicators $I_A$ and $I_B$:\n",
    "\n",
    "- $E(I_A) = P(A)$\n",
    "- $Var(I_A) = P(A)(1-P(A))$\n",
    "- $Cov(I_A, I_B) = P(AB) - P(A)P(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (Not in Textbook) ##\n",
    "Suppose you make $n$ draws at random with replacement from a population in which 60% of the individuals are red, 30% are blue, and 10% are green.\n",
    "\n",
    "Let $X$ be the number of colors that don't appear. Find $E(X)$ and $Var(X)$.\n",
    "\n",
    "The expected number of categories that don't appear ... that's a familiar calculation using indicators.\n",
    "\n",
    "$X = I_r + I_b + I_g$ where $I_r$ is the indicator of the event that the color red doesn't appear in the $n$ draws and the other two indicators are defined analogously.\n",
    "\n",
    "Then \n",
    "\n",
    "$$\n",
    "E(X) ~ = ~ 0.4^n + 0.7^n + 0.9^n\n",
    "$$\n",
    "\n",
    "$Var(X)$ is \"the sum of all the variances and all the covariances\". \n",
    "\n",
    "- $Var(I_r) = 0.4^n(1 - 0.4^n)$\n",
    "- $Cov(I_r, I_b) = 0.1^n - 0.4^n0.7^n$\n",
    "\n",
    "Add all the analogous terms:\n",
    "\n",
    "$$\n",
    "Var(X) = 0.4^n(1 - 0.4^n) + 0.7^n(1 - 0.7^n) + 0.9^n(1 - 0.9^n) + \\\\\n",
    "2\\big{(}(0.1^n - 0.4^n0.7^n) + (0.3^n - 0.4^n0.9^n) + (0.6^n - 0.7^n0.9^n)\\big{)}\n",
    "$$\n",
    "\n",
    "This is do-able, though a bit clunky to write out.\n",
    "\n",
    "When there is some symmetry in the problem, however, the variance formula simplifies greatly, as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Terms ##\n",
    "On the right hand side of the formula\n",
    "\n",
    "$$\n",
    "Var(\\sum_{i=1}^n X_i) ~ = ~ \\sum_{i=1}^n Var(X_i) ~ + ~ \\mathop{\\sum\\sum}_{1 \\le i\\ne j \\le n} Cov(X_i, X_j)\n",
    "$$\n",
    "\n",
    "- The sum of the variances has $n$ terms.\n",
    "- The sum of the covariances has $n(n-1)$ terms.\n",
    "\n",
    "(No, not $\\binom{n}{2}$ terms; you should think about why.)\n",
    "\n",
    "**If you have enough symmetry** so that the following are true:\n",
    "\n",
    "- all the individual variances are the same\n",
    "- for all pairs, the covariances are the same\n",
    "\n",
    "then the variance of the sum is just\n",
    "\n",
    "$$\n",
    "Var(\\sum_{i=1}^n X_i) ~ = ~ nVar(X_1) + n(n-1)Cov(X_1, X_2)\n",
    "$$\n",
    "\n",
    "The most signficant example, making use of symmetry in simple random sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading 2: Variance of Hypergeometric (Huge Example)\n",
    "\n",
    "Work through [this](http://prob140.org/textbook/Chapter_13/03_Sums_of_Simple_Random_Samples.html#Variance-of-the-Hypergeometric) and stop after the first line of calculation:\n",
    "\n",
    "$$\n",
    "n\\frac{G}{N}\\cdot\\frac{B}{N} + n(n-1)\\big{(}\\frac{G}{N}\\cdot\\frac{G-1}{N-1} - \\frac{G}{N}\\cdot\\frac{G}{N}\\big{)}\n",
    "$$\n",
    "\n",
    "You should be able to understand where every piece of that came from.\n",
    "\n",
    "Ignore the subsequent algebra: we'll avoid it in the next Part by doing a more general calculaton.\n",
    "\n",
    "Just go to the final result:\n",
    "\n",
    "$$\n",
    "Var(X) ~ = ~ npq\\frac{N-n}{N-1} ~~~~~~ \\text{ where } p = \\frac{G}{N}, ~q = 1-p\n",
    "$$\n",
    "\n",
    "Look at that â€“ the same as the variance of the binomial, but multiplied by a factor that is less than 1. For the same $n$ and $p$ ($=G/N$), the hypergeometric histogram is narrower than the binomial. This confirms our intuitive sense that sampling without replacement should be more accurate (less deviation from expected value) than sampling with replacement.\n",
    "\n",
    "### Example ###\n",
    "Applications are numerous: if you recognize that a random variable has a hypergeoemtric distribution, you can just plug into formulas for mean and variance.\n",
    "\n",
    "- If $X$ is the number of kings in a 5-card poker hand dealt from a standard deck, then $X$ is hypergeometric $(52, 4, 5)$. So $E(X) = 5\\cdot\\frac{4}{52}$ and $Var(X) = 5\\cdot\\frac{4}{52}\\cdot\\frac{48}{52}\\cdot\\frac{52-5}{52-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitamins ##\n",
    "\n",
    "**1.** True or false: If $Cov(I_A, I_B) < 0$ then $P(AB) < P(A)P(B)$\n",
    "\n",
    "**2.** In the formula for $Var(X_1 + X_2 + \\cdots + X_n)$, how many terms are there in the sum $\\sum_{i=1}^n Var(X_i)$?\n",
    "\n",
    "**3.** In the formula for $Var(X_1 + X_2 + \\cdots + X_n)$, how many terms are there in the sum $\\mathop{\\sum\\sum}_{1 \\le i\\ne j \\le n} Cov(X_i, X_j)$?\n",
    "\n",
    "**4.** A bowl contains 20 marbles, 14 of which are red. A simple random sample of 8 marbles is drawn. Use the code cell below to find the expectation and variance of the number of red marbles drawn. You should get 5.6 and roughly 1.061."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch work for vitamins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break time. Very clever argument coming up. ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Review Set ###\n",
    "In [Review Set 3](http://prob140.org/textbook/Chapter_15/06_Review_Problems_Set_3.html) you can now do 7, 23-27 (some of which you could also have done after Part 2), 29, 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
