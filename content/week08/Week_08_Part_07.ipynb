{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# These lines make warnings look nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Part 7 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason the i.i.d. sample mean is used so often as a basis for inference is that for a large sample the CLT tells us that that the shape of its distribution is roughly normal regardless of the population.\n",
    "\n",
    "In what follows, \"sample\" means \"i.i.d. sample\". I won't keep repeating the \"i.i.d.\" The results will also be true (or close) for samples that are almost i.i.d., like simple random samples that are a small fraction of the population. \n",
    "\n",
    "But the results might not hold if the method of sampling is different from the two described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading 1: From Sum to Average ##\n",
    "The sample average is a linear transformation of the sample sum. We already know the expectation and SD of an i.i.d. sample sum. So we can apply rules for linear transformations to find the expectation and SD of the sample mean.\n",
    "\n",
    "Go through the brief [intro](http://prob140.org/textbook/Chapter_14/04_The_Sample_Mean.html) to remind yourself of those results and to see how the distribution of the sample sum changes as the sample size increases.\n",
    "\n",
    "Now be sure you actually work through this instead of just reading: calculate the expectation and SD of the [sample mean](http://prob140.org/textbook/Chapter_14/04_The_Sample_Mean.html) and see how the distribution of the sample mean changes as the sample size increases. \n",
    "\n",
    "You should compare and contrast these changes with those for the sample sum.\n",
    "\n",
    "- $E(\\bar{X}_n) = \\mu$ for all $n$. No matter what the sample size, the distribution of the sample mean balances at $n$. For large $n$, this balance point is also the point of symmetry of the distribution, since the shape is [roughly normal](http://prob140.org/textbook/Chapter_14/04_The_Sample_Mean.html#The-Shape-of-the-Distribution).\n",
    "- Put this together with $SD(\\bar{X}_n) = \\frac{\\sigma}{\\sqrt{n}}$ to see that as the sample size increases, the distribution of the sample mean starts looking like a spike at $\\mu$.\n",
    "\n",
    "The first step to quantifying this observation is the [Square Root Law](http://prob140.org/textbook/Chapter_14/04_The_Sample_Mean.html#Square-Root-Law). \n",
    "\n",
    "If an estimator is unbiased (e.g. $\\bar{X}_n$ as an estimator of $\\mu$) then \"accurate\" can be visualized as \"small SD\". Sometimes the word \"accuracy\" is interpreted as \"1 over the SD\" so that \"more accurate\" implies \"small SD\" and vice versa.\n",
    "\n",
    "So sometimes you will see the square root law stated like this: If you increase the sample size by a factor, the accuracy increases by the square root of the factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading 2: Weak Law of Large Numbers (WLLN) ##\n",
    "In the case where the data are 0/1, this is usually called the Law of Averages.\n",
    "\n",
    "It makes precise our earlier statement that the distribution of the sample mean \"starts looking like a spike at $\\mu$\". The proof is a direct application of Chebyshev's inequality.\n",
    "\n",
    "This is another one that you shouldn't just read. Work through [the proof](http://prob140.org/textbook/Chapter_14/04_The_Sample_Mean.html#Weak-Law-of-Large-Numbers).\n",
    "\n",
    "Remember that $\\vert \\bar{X_n} - \\mu \\vert$ is the distance between $\\bar{X}_n$ and $\\mu$. That is, it's the distance between the random sample mean and the fixed population mean.\n",
    "\n",
    "So $\\vert \\bar{X_n} - \\mu \\vert < \\epsilon$ is the event that this distance is less than $\\epsilon$. This is math for \"the sample mean is very close to the population mean\" if you imagine $\\epsilon$ to be very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitamins #\n",
    "\n",
    "**1.** Match each the quantities $E(S_n)$, $E(\\bar{X}_n)$, $Var(S_n)$, $Var(\\bar{X}_n)$, $SD(S_n)$, and $SD(\\bar{X}_n)$ with the appropriate element of the following list. You may use an element once, more than once, or never.\n",
    "\n",
    "- $\\mu$, $~\\sqrt{n}\\mu$, $~n\\mu$, $~\\sigma$, $~\\sqrt{n}\\sigma$, $\\frac{\\sigma}{\\sqrt{n}}$, $~n\\sigma$, $~\\sigma^2$, $~\\sqrt{n}\\sigma^2$, $~n\\sigma^2$, $\\frac{\\sigma^2}{n}$\n",
    "\n",
    "**2.** $X_1, X_2, \\ldots, X_{100}$ are i.i.d with mean 60 and SD 2. Sketch the approximate distribution of $\\bar{X}_{100} = (X_1 + X_2 + \\cdots + X_{100})/100$. Find the numerical values of $E(\\bar{X}_{100})$ and $SD(\\bar{X}_{100})$, and show them appropriately on your sketch.\n",
    "[Compare this with Vitamin 3 of Part 5.]\n",
    "\n",
    "**3.** $X_1, X_2, \\ldots $ are i.i.d. Poisson $(5)$. When $n$ is large, the value of $\\frac{1}{n}\\sum_{i=1}^n X_i$ is highly likely to be close to one number. What's that number, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break. Final part on inference coming up. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
