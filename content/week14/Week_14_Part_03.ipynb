{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 14 Part 3 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is very short because we are skipping the main derivations. But by re-writing the formula for the simple regression estimate in an insightful way, you will be able to see how the different pieces of the formula for the multiple regression estimate arise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading: Simple Regression, Rewritten ##\n",
    "The regression slope has the SD of $X$ in the denomiator. Once $X$ becomes a vector instead of just one random variable, this will no longer work: the SD of a random vector doesn't make sense, and you can't divide by matrices.\n",
    "\n",
    "So [rewrite](http://prob140.org/textbook/Chapter_24/04_Regression_Equation.html#An-Alternative-Form) the simple regression equation, as well as the formula for the mean squared error, in a way can be generalized to the case of multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading: Multiple Regression Estimate and its Mean Squared Error ##\n",
    "Now compare the formulas above with their [counterparts](http://prob140.org/textbook/Chapter_25/03_Multivariate_Normal_Conditioning.html) in multiple regression.\n",
    "\n",
    "They are the same, except that numerical covariances and variances have been replaced by covariance vectors and matrices. Scroll down to see what the notation means.\n",
    "\n",
    "### Note on Derivation ###\n",
    "You find the conditional density by dividing the multivariate normal density of the entire vector by the multivariate normal density of $\\mathbb{X}$ alone. After algebra, this leads to a difference between quadratic forms, to simplify which you need some more linear algebra than is covered in the prerequisite classes. So just accept it, or try it out and go look up the linear algebra. But it's not required for this class.\n",
    "\n",
    "### Important ###\n",
    "The discussion is for the multivariate normal, but as in the case of simple regression, exactly the same formulas give the least squares *linear* predictor when the distribution isn't multivariate normal. That's proved in Section 24 but we'll skip it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
